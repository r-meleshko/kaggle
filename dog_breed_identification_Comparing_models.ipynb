{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-meleshko/kaggle/blob/main/dog_breed_identification_Comparing_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import NASNetLarge\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EXCv2HAMdTgM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "ssBHwATHdUWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "QP7cZW8udJAN",
        "outputId": "25abe0d9-57af-47dc-9007-a34057cac96c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-235826b9-ee28-4409-bebc-000197bd7b62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-235826b9-ee28-4409-bebc-000197bd7b62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dog-breed-identification\n",
        "!unzip dog-breed-identification.zip\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "fAlvcApNda1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test image list\n",
        "labels = pd.read_csv(\"labels.csv\")\n",
        "labels.id = labels.id.apply(lambda x: f\"{x}.jpg\")\n",
        "\n",
        "train_df, validation_df = train_test_split(labels, stratify=labels['breed'], test_size=0.2, random_state=420)\n",
        "\n",
        "# Create test generator\n",
        "test_filenames = os.listdir('test')\n",
        "test_df = pd.DataFrame({'id': test_filenames})\n",
        "\n",
        "labels.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "4KG3kmM7dzyc",
        "outputId": "cc1504c0-c089-4491-a3ce-5741a5b4e53d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id        breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07.jpg  boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97.jpg        dingo"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-007107f4-0379-4c3c-968d-9b3c2e1809f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07.jpg</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97.jpg</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-007107f4-0379-4c3c-968d-9b3c2e1809f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4f5cb815-560a-406a-a287-ab1f9908d847\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f5cb815-560a-406a-a287-ab1f9908d847')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4f5cb815-560a-406a-a287-ab1f9908d847 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-007107f4-0379-4c3c-968d-9b3c2e1809f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-007107f4-0379-4c3c-968d-9b3c2e1809f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_generators(img_size):\n",
        "    \"\"\"Create test, validation and train generators with image size appropriate for each model.\"\"\"\n",
        "    batch_size = 32\n",
        "\n",
        "    # Create a data generator with data augmentaiton\n",
        "    train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "    # Prepare the generators for train and validation datasets\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory='train',\n",
        "        x_col=\"id\",\n",
        "        y_col=\"breed\",\n",
        "        target_size=img_size,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    validation_datagen = ImageDataGenerator()\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        directory='train',\n",
        "        x_col=\"id\",\n",
        "        y_col=\"breed\",\n",
        "        target_size=img_size,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator()\n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,  # the dataframe for the test set will be created later\n",
        "        directory='test',\n",
        "        x_col=\"id\",\n",
        "        class_mode=None,  # no labels\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False  # keep data in the same order as filenames\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator, test_generator"
      ],
      "metadata": {
        "id": "cXnFPiL4d19f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "Va-Q7uQrjNQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import models"
      ],
      "metadata": {
        "id": "riHS57iNjNCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "InceptionV3_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "Xception_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input\n",
        "NASNetLarge_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "InceptionResNetV2_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "VGG19_preprocessor = preprocess_input\n",
        "\n",
        "\n",
        "input_shapes = {\n",
        "    \"InceptionV3\": (299, 299),\n",
        "    \"Xception\": (299, 299),\n",
        "    \"NASNetLarge\": (331, 331),\n",
        "    \"InceptionResNetV2\": (299, 299),\n",
        "    \"VGG19\": (224, 224),\n",
        "}\n",
        "\n",
        "models = [InceptionV3, Xception, NASNetLarge, InceptionResNetV2, VGG19]"
      ],
      "metadata": {
        "id": "IjOqDYprjMf-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation function"
      ],
      "metadata": {
        "id": "WoYjcW1ajn-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "\n",
        "def kaggle_submission(model, name, test_generator, test_df):\n",
        "    # Submit results to Kaggle\n",
        "    pred = model.predict(test_generator)\n",
        "    submission = pd.read_csv(\"sample_submission.csv\")\n",
        "    submission = pd.DataFrame(pred, columns=submission.columns[1:])\n",
        "    submission.insert(0, \"id\", test_df.id)\n",
        "    submission.id = submission.id.str.rstrip('.jpg')\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    !kaggle competitions submit -c dog-breed-identification -f submission.csv -m f\"Evaluating models: {name} (2).\""
      ],
      "metadata": {
        "id": "O3LCu-ULn_a6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(models: list) -> tuple:\n",
        "    performance = dict()\n",
        "\n",
        "    for pretrained_model in models:\n",
        "        name = pretrained_model.__name__\n",
        "        print(f'\\nEvaluating {name} model.')\n",
        "\n",
        "        # Model specific parameters\n",
        "        img_size = input_shapes[name]\n",
        "        train_generator, validation_generator, test_generator = create_data_generators(img_size)\n",
        "        preprocessor = eval(f\"{name}_preprocessor\")\n",
        "\n",
        "        model_weights = pretrained_model(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "        model_weights.trainable = False\n",
        "\n",
        "        # Define model\n",
        "        model = keras.Sequential([\n",
        "            layers.Lambda(preprocessor),\n",
        "            model_weights,\n",
        "            layers.GlobalAveragePooling2D(),\n",
        "            layers.Dense(512, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(120, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "        # Define callbacks\n",
        "        time_callback = TimeHistory()\n",
        "        earlystop = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=1, min_delta=0.01, restore_best_weights=True)\n",
        "        callbacks_list = [earlystop, time_callback]\n",
        "\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=train_generator,\n",
        "            epochs=5,\n",
        "            callbacks=callbacks_list\n",
        "        )\n",
        "\n",
        "        performance[name] = model.evaluate(validation_generator) + [np.mean(time_callback.times), model, history]\n",
        "        print(performance[name][:3])\n",
        "\n",
        "        if performance[name][1] > 0.8:\n",
        "            kaggle_submission(model, name, test_generator, test_df)\n",
        "\n",
        "\n",
        "    return performance"
      ],
      "metadata": {
        "id": "WPxzS0qpjLuo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "df429794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e8157b-6ffc-46d6-e052-7120424f9f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating InceptionV3 model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 120s 444ms/step - loss: 1.5107 - accuracy: 0.6621 - val_loss: 0.3316 - val_accuracy: 0.9007\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 112s 437ms/step - loss: 0.5503 - accuracy: 0.8382 - val_loss: 0.2662 - val_accuracy: 0.9181\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 111s 433ms/step - loss: 0.4488 - accuracy: 0.8614 - val_loss: 0.2575 - val_accuracy: 0.9107\n",
            "64/64 [==============================] - 14s 209ms/step - loss: 0.3980 - accuracy: 0.8719\n",
            "[0.39798805117607117, 0.8718826174736023, 114.2386618455251]\n",
            "324/324 [==============================] - 67s 202ms/step\n",
            "100% 16.4M/16.4M [00:04<00:00, 3.46MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating Xception model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 5s 0us/step\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 137s 511ms/step - loss: 1.2329 - accuracy: 0.7206 - val_loss: 0.3154 - val_accuracy: 0.9005\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 148s 578ms/step - loss: 0.4334 - accuracy: 0.8677 - val_loss: 0.2493 - val_accuracy: 0.9221\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 129s 505ms/step - loss: 0.3519 - accuracy: 0.8888 - val_loss: 0.2039 - val_accuracy: 0.9307\n",
            "64/64 [==============================] - 19s 295ms/step - loss: 0.3988 - accuracy: 0.8768\n",
            "[0.39883479475975037, 0.8767726421356201, 137.94217586517334]\n",
            "324/324 [==============================] - 83s 255ms/step\n",
            "100% 16.4M/16.4M [00:04<00:00, 3.77MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating NASNetLarge model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
            "343610240/343610240 [==============================] - 16s 0us/step\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 466s 2s/step - loss: 0.6922 - accuracy: 0.8547 - val_loss: 0.1923 - val_accuracy: 0.9447\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 434s 2s/step - loss: 0.2703 - accuracy: 0.9263 - val_loss: 0.1578 - val_accuracy: 0.9499\n",
            "64/64 [==============================] - 57s 893ms/step - loss: 0.2744 - accuracy: 0.9242\n",
            "[0.27439984679222107, 0.9242053627967834, 449.8481092453003]\n",
            "324/324 [==============================] - 279s 847ms/step\n",
            "100% 16.4M/16.4M [00:03<00:00, 4.71MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating InceptionResNetV2 model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219055592/219055592 [==============================] - 12s 0us/step\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 183s 664ms/step - loss: 1.0305 - accuracy: 0.7789 - val_loss: 0.2937 - val_accuracy: 0.9113\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 164s 642ms/step - loss: 0.4138 - accuracy: 0.8855 - val_loss: 0.2309 - val_accuracy: 0.9263\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 164s 643ms/step - loss: 0.3558 - accuracy: 0.8958 - val_loss: 0.2192 - val_accuracy: 0.9293\n",
            "64/64 [==============================] - 23s 351ms/step - loss: 0.3377 - accuracy: 0.9017\n",
            "[0.33765947818756104, 0.9017114639282227, 170.4936998685201]\n",
            "324/324 [==============================] - 110s 328ms/step\n",
            "100% 16.4M/16.4M [00:04<00:00, 3.51MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating VGG19 model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 5s 0us/step\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 102s 374ms/step - loss: 4.4729 - accuracy: 0.1738 - val_loss: 1.8041 - val_accuracy: 0.5421\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 92s 361ms/step - loss: 2.3124 - accuracy: 0.4054 - val_loss: 1.1403 - val_accuracy: 0.6981\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 92s 361ms/step - loss: 1.7717 - accuracy: 0.5119 - val_loss: 0.8890 - val_accuracy: 0.7542\n",
            "Epoch 4/5\n",
            "256/256 [==============================] - 92s 361ms/step - loss: 1.5383 - accuracy: 0.5687 - val_loss: 0.7537 - val_accuracy: 0.7818\n",
            "Epoch 5/5\n",
            "256/256 [==============================] - 92s 359ms/step - loss: 1.3652 - accuracy: 0.6033 - val_loss: 0.6398 - val_accuracy: 0.8148\n",
            "64/64 [==============================] - 16s 254ms/step - loss: 1.2777 - accuracy: 0.6313\n",
            "[1.2777432203292847, 0.6312958598136902, 94.1251413345337]\n"
          ]
        }
      ],
      "source": [
        "performance = compare_models(models)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in performance:\n",
        "    loss, acc, etime = [round(x, 2) for x in performance[i][:3]]\n",
        "    print(f'Model: {i} | Val. accuracy: {acc} | Time per epoch {etime}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nme5xhV1mip",
        "outputId": "761ba503-0531-4cb9-850c-f4bf49812d20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: InceptionV3 | Val. accuracy: 0.87 | Time per epoch 114.24\n",
            "\n",
            "Model: Xception | Val. accuracy: 0.88 | Time per epoch 137.94\n",
            "\n",
            "Model: NASNetLarge | Val. accuracy: 0.92 | Time per epoch 449.85\n",
            "\n",
            "Model: InceptionResNetV2 | Val. accuracy: 0.9 | Time per epoch 170.49\n",
            "\n",
            "Model: VGG19 | Val. accuracy: 0.63 | Time per epoch 94.13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submissions -c dog-breed-identification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXs9GfA0V5tl",
        "outputId": "d9f58a62-b77e-4a67-f988-129352c7f5ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName        date                 description                                                 status    publicScore  privateScore  \n",
            "--------------  -------------------  ----------------------------------------------------------  --------  -----------  ------------  \n",
            "submission.csv  2023-07-26 09:15:42  fEvaluating models: InceptionResNetV2 (2).                  complete  0.30361      0.30361       \n",
            "submission.csv  2023-07-26 09:03:47  fEvaluating models: NASNetLarge (2).                        complete  0.26150      0.26150       \n",
            "submission.csv  2023-07-26 08:41:12  fEvaluating models: Xception (2).                           complete  0.37678      0.37678       \n",
            "submission.csv  2023-07-26 08:32:19  fEvaluating models: InceptionV3 (2).                        complete  0.38870      0.38870       \n",
            "submission.csv  2023-07-25 22:24:49  fEvaluating models: InceptionResNetV2.                      complete  5.21092      5.21092       \n",
            "submission.csv  2023-07-25 22:16:16  fEvaluating models: NASNetLarge.                            complete  5.15124      5.15124       \n",
            "submission.csv  2023-07-25 21:55:15  fEvaluating models: Xception.                               complete  5.10537      5.10537       \n",
            "submission.csv  2023-07-25 21:44:39  fEvaluating models: InceptionV3.                            complete  5.13714      5.13714       \n",
            "submission.csv  2023-07-25 17:29:48  First submission using transfer learning with NASNetLarge.  complete  0.32376      0.32376       \n"
          ]
        }
      ]
    }
  ]
}