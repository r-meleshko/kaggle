{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNI9QJwvJpsbe2p8isctyIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-meleshko/kaggle/blob/main/dog_breed_identification_Comparing_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import NASNetLarge\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EXCv2HAMdTgM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "ssBHwATHdUWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "QP7cZW8udJAN",
        "outputId": "8aaed35f-d174-4c57-8a5e-db8c4a134ee9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2063dd4d-622a-4503-ac8b-25f24f8207b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2063dd4d-622a-4503-ac8b-25f24f8207b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dog-breed-identification\n",
        "!unzip dog-breed-identification.zip\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "fAlvcApNda1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test image list\n",
        "labels = pd.read_csv(\"labels.csv\")\n",
        "labels.id = labels.id.apply(lambda x: f\"{x}.jpg\")\n",
        "\n",
        "train_df, validation_df = train_test_split(labels, stratify=labels['breed'], test_size=0.2, random_state=420)\n",
        "\n",
        "# Create test generator\n",
        "test_filenames = os.listdir('test')\n",
        "test_df = pd.DataFrame({'id': test_filenames})\n",
        "\n",
        "labels.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "4KG3kmM7dzyc",
        "outputId": "96684e2f-104f-4e9f-d4a5-fb7c54b4d168"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id        breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07.jpg  boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97.jpg        dingo"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6409c4a0-3438-49c7-bc43-9e14bf1a7ca4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07.jpg</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97.jpg</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6409c4a0-3438-49c7-bc43-9e14bf1a7ca4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4a0961cf-bd08-4b30-971a-036648933cd2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a0961cf-bd08-4b30-971a-036648933cd2')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4a0961cf-bd08-4b30-971a-036648933cd2 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6409c4a0-3438-49c7-bc43-9e14bf1a7ca4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6409c4a0-3438-49c7-bc43-9e14bf1a7ca4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_generators(img_size):\n",
        "    \"\"\"Create test, validation and train generators with image size appropriate for each model.\"\"\"\n",
        "    batch_size = 32\n",
        "\n",
        "    # Create a data generator with data augmentaiton\n",
        "    train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "    # Prepare the generators for train and validation datasets\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory='train',\n",
        "        x_col=\"id\",\n",
        "        y_col=\"breed\",\n",
        "        target_size=img_size,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    validation_datagen = ImageDataGenerator()\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        directory='train',\n",
        "        x_col=\"id\",\n",
        "        y_col=\"breed\",\n",
        "        target_size=img_size,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,  # the dataframe for the test set will be created later\n",
        "        directory='test',\n",
        "        x_col=\"id\",\n",
        "        class_mode=None,  # no labels\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False  # keep data in the same order as filenames\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator, test_generator"
      ],
      "metadata": {
        "id": "cXnFPiL4d19f"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "Va-Q7uQrjNQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import models"
      ],
      "metadata": {
        "id": "riHS57iNjNCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "InceptionV3_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "Xception_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input\n",
        "NASNetLarge_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "InceptionResNetV2_preprocessor = preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "VGG19_preprocessor = preprocess_input\n",
        "\n",
        "\n",
        "input_shapes = {\n",
        "    \"InceptionV3\": (299, 299),\n",
        "    \"Xception\": (299, 299),\n",
        "    \"NASNetLarge\": (331, 331),\n",
        "    \"InceptionResNetV2\": (299, 299),\n",
        "    \"VGG19\": (224, 224),\n",
        "}\n",
        "\n",
        "models = [InceptionV3, Xception, NASNetLarge, InceptionResNetV2, VGG19]"
      ],
      "metadata": {
        "id": "IjOqDYprjMf-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation function"
      ],
      "metadata": {
        "id": "WoYjcW1ajn-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "\n",
        "def kaggle_submission(model, name, test_generator, test_df):\n",
        "    # Submit results to Kaggle\n",
        "    pred = model.predict(test_generator)\n",
        "    submission = pd.read_csv(\"sample_submission.csv\")\n",
        "    submission = pd.DataFrame(pred, columns=submission.columns[1:])\n",
        "    submission.insert(0, \"id\", test_df.id)\n",
        "    submission.id = submission.id.str.rstrip('.jpg')\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    !kaggle competitions submit -c dog-breed-identification -f submission.csv -m f\"Evaluating models: {name}.\""
      ],
      "metadata": {
        "id": "O3LCu-ULn_a6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(models: list) -> tuple:\n",
        "    performance = dict()\n",
        "\n",
        "    for pretrained_model in models:\n",
        "        name = pretrained_model.__name__\n",
        "        print(f'\\nEvaluating {name} model.')\n",
        "\n",
        "        # Model specific parameters\n",
        "        img_size = input_shapes[name]\n",
        "        train_generator, validation_generator, test_generator = create_data_generators(img_size)\n",
        "        preprocessor = eval(f\"{name}_preprocessor\")\n",
        "\n",
        "        model_weights = pretrained_model(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "        model_weights.trainable = False\n",
        "\n",
        "        # Define model\n",
        "        model = keras.Sequential([\n",
        "            layers.Lambda(preprocessor),\n",
        "            model_weights,\n",
        "            layers.GlobalAveragePooling2D(),\n",
        "            layers.Dense(512, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(120, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "        # Define callbacks\n",
        "        time_callback = TimeHistory()\n",
        "        earlystop = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=1, min_delta=0.01, restore_best_weights=True)\n",
        "        callbacks_list = [earlystop, time_callback]\n",
        "\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=train_generator,\n",
        "            epochs=5,\n",
        "            callbacks=callbacks_list\n",
        "        )\n",
        "\n",
        "        performance[name] = model.evaluate(validation_generator) + [np.mean(time_callback.times)]\n",
        "        print(performance[name])\n",
        "\n",
        "        if performance[name][1] > 0.8:\n",
        "            kaggle_submission(model, name, test_generator, test_df)\n",
        "\n",
        "\n",
        "    return performance"
      ],
      "metadata": {
        "id": "WPxzS0qpjLuo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "df429794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4597b4-48b5-4e2c-fe73-919152a556e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating InceptionV3 model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 119s 439ms/step - loss: 1.4842 - accuracy: 0.6658 - val_loss: 0.3877 - val_accuracy: 0.8870\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 113s 440ms/step - loss: 0.5313 - accuracy: 0.8408 - val_loss: 0.2651 - val_accuracy: 0.9119\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 112s 440ms/step - loss: 0.4444 - accuracy: 0.8623 - val_loss: 0.2181 - val_accuracy: 0.9300\n",
            "Epoch 4/5\n",
            "256/256 [==============================] - 111s 435ms/step - loss: 0.3935 - accuracy: 0.8782 - val_loss: 0.1951 - val_accuracy: 0.9332\n",
            "64/64 [==============================] - 14s 213ms/step - loss: 0.3837 - accuracy: 0.8812\n",
            "[0.3836955428123474, 0.8811736106872559, 113.88543891906738]\n",
            "324/324 [==============================] - 73s 222ms/step\n",
            "100% 15.0M/15.0M [00:01<00:00, 9.62MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating Xception model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 134s 508ms/step - loss: 1.2345 - accuracy: 0.7212 - val_loss: 0.3062 - val_accuracy: 0.9097\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 127s 498ms/step - loss: 0.4272 - accuracy: 0.8718 - val_loss: 0.2422 - val_accuracy: 0.9255\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 128s 502ms/step - loss: 0.3585 - accuracy: 0.8880 - val_loss: 0.1949 - val_accuracy: 0.9373\n",
            "Epoch 4/5\n",
            "256/256 [==============================] - 127s 496ms/step - loss: 0.3098 - accuracy: 0.9016 - val_loss: 0.1745 - val_accuracy: 0.9393\n",
            "64/64 [==============================] - 16s 247ms/step - loss: 0.3826 - accuracy: 0.8748\n",
            "[0.38255584239959717, 0.8748165965080261, 129.18969237804413]\n",
            "324/324 [==============================] - 83s 253ms/step\n",
            "100% 15.0M/15.0M [00:01<00:00, 10.0MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating NASNetLarge model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 455s 2s/step - loss: 0.7223 - accuracy: 0.8514 - val_loss: 0.1884 - val_accuracy: 0.9468\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 430s 2s/step - loss: 0.2536 - accuracy: 0.9294 - val_loss: 0.1592 - val_accuracy: 0.9519\n",
            "64/64 [==============================] - 57s 882ms/step - loss: 0.2828 - accuracy: 0.9198\n",
            "[0.2827793061733246, 0.9198043942451477, 442.43012487888336]\n",
            "324/324 [==============================] - 273s 829ms/step\n",
            "100% 15.0M/15.0M [00:01<00:00, 8.29MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating InceptionResNetV2 model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219055592/219055592 [==============================] - 7s 0us/step\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 181s 651ms/step - loss: 1.0360 - accuracy: 0.7810 - val_loss: 0.2887 - val_accuracy: 0.9128\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 163s 638ms/step - loss: 0.4087 - accuracy: 0.8863 - val_loss: 0.2360 - val_accuracy: 0.9215\n",
            "64/64 [==============================] - 22s 349ms/step - loss: 0.3785 - accuracy: 0.8861\n",
            "[0.3785027861595154, 0.8860635757446289, 171.9440916776657]\n",
            "324/324 [==============================] - 106s 318ms/step\n",
            "100% 15.0M/15.0M [00:01<00:00, 8.89MB/s]\n",
            "Successfully submitted to Dog Breed Identification\n",
            "Evaluating VGG19 model.\n",
            "Found 8177 validated image filenames belonging to 120 classes.\n",
            "Found 2045 validated image filenames belonging to 120 classes.\n",
            "Found 10357 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 3s 0us/step\n",
            "Epoch 1/5\n",
            "256/256 [==============================] - 98s 360ms/step - loss: 4.5338 - accuracy: 0.1655 - val_loss: 1.8824 - val_accuracy: 0.5349\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 90s 350ms/step - loss: 2.3391 - accuracy: 0.4102 - val_loss: 1.1950 - val_accuracy: 0.6775\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 128s 502ms/step - loss: 1.8147 - accuracy: 0.5100 - val_loss: 0.8957 - val_accuracy: 0.7508\n",
            "Epoch 4/5\n",
            "256/256 [==============================] - 89s 347ms/step - loss: 1.5423 - accuracy: 0.5628 - val_loss: 0.7409 - val_accuracy: 0.7922\n",
            "Epoch 5/5\n",
            "256/256 [==============================] - 88s 346ms/step - loss: 1.3884 - accuracy: 0.6024 - val_loss: 0.6228 - val_accuracy: 0.8189\n",
            "64/64 [==============================] - 15s 233ms/step - loss: 1.2342 - accuracy: 0.6347\n",
            "[1.2342033386230469, 0.6347188353538513, 98.66403565406799]\n"
          ]
        }
      ],
      "source": [
        "performance = compare_models(models)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in performance:\n",
        "    loss, acc, etime = [round(x, 2) for x in performance[i]]\n",
        "    print(f'Model: {i} | Val. accuracy: {acc} | Time per epoch {etime}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nme5xhV1mip",
        "outputId": "f56a9b3b-360b-4ee8-d27f-04b7d7534305"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: InceptionV3 | Val. accuracy: 0.88 | Time per epoch 113.89\n",
            "\n",
            "Model: Xception | Val. accuracy: 0.87 | Time per epoch 129.19\n",
            "\n",
            "Model: NASNetLarge | Val. accuracy: 0.92 | Time per epoch 442.43\n",
            "\n",
            "Model: InceptionResNetV2 | Val. accuracy: 0.89 | Time per epoch 171.94\n",
            "\n",
            "Model: VGG19 | Val. accuracy: 0.63 | Time per epoch 98.66\n",
            "\n"
          ]
        }
      ]
    }
  ]
}